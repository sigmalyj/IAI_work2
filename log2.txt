------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (14270 examples) in 0.547s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 14270
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 1 in 21.578s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (14950 examples) in 0.581s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 29220
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 20.725s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (14290 examples) in 0.562s, Win: 8, Draw: 1, Lose: 11
[TRAIN DATA SIZE]: 43510
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 3 in 25.066s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (13470 examples) in 0.566s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 56980
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 20.372s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (13620 examples) in 0.655s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 70600
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 17.013s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (13590 examples) in 0.508s, Win: 13, Draw: 0, Lose: 7
[TRAIN DATA SIZE]: 84190
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose2, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 6 in 23.240s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (12850 examples) in 0.510s, Win: 8, Draw: 1, Lose: 11
[TRAIN DATA SIZE]: 97040
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose4, draw0
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 7 in 27.806s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (13420 examples) in 0.533s, Win: 11, Draw: 2, Lose: 7
[TRAIN DATA SIZE]: 110460
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 23.023s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (13050 examples) in 0.493s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 123510
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose1, draw1
[EVALUATION RESULT]:(first)  win9, lose0, draw1
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 9 in 24.846s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (14620 examples) in 0.606s, Win: 15, Draw: 0, Lose: 5
[TRAIN DATA SIZE]: 138130
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 10 in 18.021s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (14970 examples) in 0.806s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 153100
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 11 in 25.723s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (13980 examples) in 0.561s, Win: 15, Draw: 2, Lose: 3
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 12 in 20.247s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (14900 examples) in 0.590s, Win: 14, Draw: 1, Lose: 5
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose0, draw1
[EVALUATION RESULT]:(first)  win9, lose0, draw1
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 13 in 27.062s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (14270 examples) in 0.619s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 14 in 24.433s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (15080 examples) in 0.662s, Win: 13, Draw: 0, Lose: 7
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 15 in 31.090s ------

------ Start Self-Play Iteration 16 ------
[AlphaZeroParallel] Finished 20 episodes (14950 examples) in 0.691s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 16 in 28.262s ------

------ Start Self-Play Iteration 17 ------
[AlphaZeroParallel] Finished 20 episodes (14020 examples) in 0.547s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 17 in 17.971s ------

------ Start Self-Play Iteration 18 ------
[AlphaZeroParallel] Finished 20 episodes (14710 examples) in 0.593s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 18 in 23.225s ------

------ Start Self-Play Iteration 19 ------
[AlphaZeroParallel] Finished 20 episodes (13430 examples) in 0.555s, Win: 15, Draw: 0, Lose: 5
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose2, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 19 in 26.502s ------

------ Start Self-Play Iteration 20 ------
[AlphaZeroParallel] Finished 20 episodes (13500 examples) in 0.497s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 20 in 26.104s ------

------ Start Self-Play Iteration 21 ------
[AlphaZeroParallel] Finished 20 episodes (14700 examples) in 0.638s, Win: 14, Draw: 1, Lose: 5
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 21 in 25.828s ------

------ Start Self-Play Iteration 22 ------
[AlphaZeroParallel] Finished 20 episodes (14730 examples) in 0.589s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose3, draw1
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win8, lose1, draw1
------ Finished Self-Play Iteration 22 in 26.802s ------

------ Start Self-Play Iteration 23 ------
[AlphaZeroParallel] Finished 20 episodes (14590 examples) in 0.622s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose1, draw1
[EVALUATION RESULT]:(first)  win8, lose1, draw1
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 23 in 28.575s ------

------ Start Self-Play Iteration 24 ------
[AlphaZeroParallel] Finished 20 episodes (13500 examples) in 0.507s, Win: 14, Draw: 1, Lose: 5
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 24 in 26.476s ------

------ Start Self-Play Iteration 25 ------
[AlphaZeroParallel] Finished 20 episodes (13340 examples) in 0.827s, Win: 11, Draw: 2, Lose: 7
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 25 in 26.444s ------

------ Start Self-Play Iteration 26 ------
[AlphaZeroParallel] Finished 20 episodes (13970 examples) in 0.571s, Win: 12, Draw: 3, Lose: 5
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 26 in 28.902s ------

------ Start Self-Play Iteration 27 ------
[AlphaZeroParallel] Finished 20 episodes (14590 examples) in 0.562s, Win: 9, Draw: 1, Lose: 10
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 27 in 29.264s ------

------ Start Self-Play Iteration 28 ------
[AlphaZeroParallel] Finished 20 episodes (14540 examples) in 0.543s, Win: 13, Draw: 0, Lose: 7
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 28 in 24.992s ------

------ Start Self-Play Iteration 29 ------
[AlphaZeroParallel] Finished 20 episodes (14580 examples) in 0.622s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 29 in 25.418s ------

------ Start Self-Play Iteration 30 ------
[AlphaZeroParallel] Finished 20 episodes (13350 examples) in 0.644s, Win: 13, Draw: 0, Lose: 7
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 30 in 23.770s ------

------ Start Self-Play Iteration 31 ------
[AlphaZeroParallel] Finished 20 episodes (14760 examples) in 0.619s, Win: 12, Draw: 2, Lose: 6
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 31 in 21.791s ------

------ Start Self-Play Iteration 32 ------
[AlphaZeroParallel] Finished 20 episodes (14500 examples) in 0.686s, Win: 7, Draw: 2, Lose: 11
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 32 in 29.314s ------

------ Start Self-Play Iteration 33 ------
[AlphaZeroParallel] Finished 20 episodes (14410 examples) in 0.704s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 33 in 34.475s ------

------ Start Self-Play Iteration 34 ------
[AlphaZeroParallel] Finished 20 episodes (14050 examples) in 0.654s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose2, draw1
[EVALUATION RESULT]:(first)  win7, lose2, draw1
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 34 in 31.304s ------

------ Start Self-Play Iteration 35 ------
[AlphaZeroParallel] Finished 20 episodes (11920 examples) in 0.459s, Win: 8, Draw: 1, Lose: 11
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 35 in 28.652s ------

------ Start Self-Play Iteration 36 ------
[AlphaZeroParallel] Finished 20 episodes (13970 examples) in 0.637s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose4, draw2
[EVALUATION RESULT]:(first)  win8, lose1, draw1
[EVALUATION RESULT]:(second) win6, lose3, draw1
------ Finished Self-Play Iteration 36 in 32.579s ------

------ Start Self-Play Iteration 37 ------
[AlphaZeroParallel] Finished 20 episodes (16590 examples) in 0.756s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 37 in 25.381s ------

------ Start Self-Play Iteration 38 ------
[AlphaZeroParallel] Finished 20 episodes (13970 examples) in 0.895s, Win: 8, Draw: 1, Lose: 11
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose1, draw1
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win8, lose1, draw1
------ Finished Self-Play Iteration 38 in 31.470s ------

------ Start Self-Play Iteration 39 ------
[AlphaZeroParallel] Finished 20 episodes (14570 examples) in 0.546s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 39 in 29.516s ------

------ Start Self-Play Iteration 40 ------
[AlphaZeroParallel] Finished 20 episodes (13060 examples) in 0.515s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose2, draw1
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win7, lose2, draw1
------ Finished Self-Play Iteration 40 in 25.689s ------

------ Start Self-Play Iteration 41 ------
[AlphaZeroParallel] Finished 20 episodes (14320 examples) in 0.593s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 41 in 26.578s ------

------ Start Self-Play Iteration 42 ------
[AlphaZeroParallel] Finished 20 episodes (13250 examples) in 0.656s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 42 in 25.910s ------

------ Start Self-Play Iteration 43 ------
[AlphaZeroParallel] Finished 20 episodes (13250 examples) in 0.606s, Win: 9, Draw: 1, Lose: 10
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 43 in 22.199s ------

------ Start Self-Play Iteration 44 ------
[AlphaZeroParallel] Finished 20 episodes (14990 examples) in 0.743s, Win: 8, Draw: 0, Lose: 12
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose4, draw0
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 44 in 33.208s ------

------ Start Self-Play Iteration 45 ------
[AlphaZeroParallel] Finished 20 episodes (16430 examples) in 0.614s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 45 in 31.980s ------

------ Start Self-Play Iteration 46 ------
[AlphaZeroParallel] Finished 20 episodes (13210 examples) in 0.509s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 46 in 29.376s ------

------ Start Self-Play Iteration 47 ------
[AlphaZeroParallel] Finished 20 episodes (14270 examples) in 0.676s, Win: 12, Draw: 2, Lose: 6
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 47 in 31.399s ------

------ Start Self-Play Iteration 48 ------
[AlphaZeroParallel] Finished 20 episodes (15240 examples) in 0.651s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win12, lose8, draw0
[EVALUATION RESULT]:(first)  win6, lose4, draw0
[EVALUATION RESULT]:(second) win6, lose4, draw0
------ Finished Self-Play Iteration 48 in 33.859s ------

------ Start Self-Play Iteration 49 ------
[AlphaZeroParallel] Finished 20 episodes (15580 examples) in 0.766s, Win: 15, Draw: 0, Lose: 5
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 49 in 34.553s ------

------ Start Self-Play Iteration 50 ------
[AlphaZeroParallel] Finished 20 episodes (12980 examples) in 0.563s, Win: 9, Draw: 1, Lose: 10
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 50 in 26.840s ------

