------ Start Self-Play Iteration 1 ------
[NEW TRAIN DATA COLLECTED]: Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 12220
------ Start Self-Play Iteration 1 ------
[NEW TRAIN DATA COLLECTED]: Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 12220
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Start Self-Play Iteration 2 ------
[NEW TRAIN DATA COLLECTED]: Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 26620
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (14270 examples) in 0.548s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 14270
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 1 in 21.845s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (14780 examples) in 0.564s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 29050
[AlphaZeroParallel] Start evaluating with last best model for 20 round
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (14270 examples) in 0.559s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 14270
[AlphaZeroParallel] Start evaluating with last best model for 20 round
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (14270 examples) in 0.497s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 14270
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 1 in 22.921s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (14780 examples) in 0.547s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 29050
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 2 in 23.561s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (14740 examples) in 0.597s, Win: 15, Draw: 1, Lose: 4
[TRAIN DATA SIZE]: 43790
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 21.064s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (14800 examples) in 0.635s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 58590
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose1, draw1
[EVALUATION RESULT]:(first)  win8, lose1, draw1
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 4 in 23.242s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (14950 examples) in 0.600s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 73540
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose0, draw2
[EVALUATION RESULT]:(first)  win9, lose0, draw1
[EVALUATION RESULT]:(second) win9, lose0, draw1
------ Finished Self-Play Iteration 5 in 32.036s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (14100 examples) in 0.635s, Win: 15, Draw: 0, Lose: 5
[TRAIN DATA SIZE]: 87640
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 18.177s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (13710 examples) in 0.514s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 101350
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 20.072s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (13380 examples) in 0.510s, Win: 13, Draw: 0, Lose: 7
[TRAIN DATA SIZE]: 114730
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 8 in 22.967s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (13050 examples) in 0.519s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 127780
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 9 in 27.465s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (14540 examples) in 0.663s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 142320
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 10 in 22.140s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (12980 examples) in 0.709s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 155300
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 11 in 28.840s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (15720 examples) in 0.571s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 12 in 27.813s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (12570 examples) in 0.541s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 160000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
